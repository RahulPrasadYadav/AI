{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefac2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "santence=\"Rahul Verma, a software engineer at Infosys, traveled from Bengaluru to New Delhi on 12 March 2024 to attend a technology conference. The event was organized by NASSCOM at Pragati Maidan, where experts from Google, Microsoft, and Amazon discussed advancements in Artificial Intelligence. Rahul booked his flight through MakeMyTrip for â‚¹18,500 and stayed at Hotel Leela Palace for two nights.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea786cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7bd5049",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=word_tokenize(santence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25cde21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\yrahu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\yrahu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     C:\\Users\\yrahu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\yrahu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download required NLTK data for POS tagging and NER\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('perluniprops')\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a0db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teg_element=nltk.pos_tag(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267fabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.ne_chunk(teg_element).draw()\n",
    "# Uncomment the line below if you want to visualize the tree (requires Tkinter)\n",
    "# ne_tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a158ea",
   "metadata": {},
   "source": [
    "data ---->>>>> text prepreprocessing  -1\n",
    "\n",
    "\n",
    "1 -> tekonization\n",
    "\n",
    "2-> lowercase the word \n",
    "\n",
    "3---> reguler expration \n",
    "\n",
    "\n",
    "\n",
    "data ---->>>>> text prepreprocessing  -2\n",
    "\n",
    "\n",
    "1=> Stemming \n",
    "\n",
    "2-> Lemitization\n",
    "\n",
    "3=> stopword \n",
    "\n",
    "\n",
    "textt----->>> Vector \n",
    "there is technique  we used \n",
    "\n",
    "1=>> one hot encoding\n",
    "\n",
    "2=>> bag of word (BOW)\n",
    "\n",
    "3=> TF-IDF \n",
    "\n",
    "4=> word2Vec\n",
    "\n",
    "5=> avg  word2 vec \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470252b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31063611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
